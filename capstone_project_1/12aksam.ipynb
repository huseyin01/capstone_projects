{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket='nlptrial'\n",
    "data_key = 'amazontrial.csv'\n",
    "data_location = 's3://{}/{}'.format(bucket, data_key)\n",
    "\n",
    "df = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "## Regular Expression\n",
    "import re\n",
    "\n",
    "## Arrays\n",
    "import numpy as np\n",
    "\n",
    "## DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "## Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    12080\n",
       "0     1192\n",
       "Name: rating_class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_text']\n",
    "y = df['rating_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect1 = CountVectorizer(ngram_range=(1,1))\n",
    "count_vect_train1 = count_vect1.fit_transform(X_train)\n",
    "count_vect_train1 = count_vect_train1.toarray()\n",
    "count_vect_test1 = count_vect1.transform(X_test)\n",
    "count_vect_test1 = count_vect_test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.29 µs\n",
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.9116937914406269\n",
      "\n",
      "2. The F-1 score of the model 0.9059372008983804\n",
      "\n",
      "3. The recall score of the model 0.9116937914406269\n",
      "\n",
      "4. Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.50      0.38      0.43       293\n",
      "          1       0.94      0.96      0.95      3025\n",
      "\n",
      "avg / total       0.90      0.91      0.91      3318\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 110  183]\n",
      " [ 110 2915]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [Linear SVM] **********\n",
      "\n",
      "1. Accuarcy: 0.8945147679324894\n",
      "\n",
      "2. The F-1 score of the model 0.8963798270485961\n",
      "\n",
      "3. The recall score of the model 0.8945147679324894\n",
      "\n",
      "4. Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.41      0.44      0.43       293\n",
      "          1       0.95      0.94      0.94      3025\n",
      "\n",
      "avg / total       0.90      0.89      0.90      3318\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 130  163]\n",
      " [ 187 2838]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [Naive Bayes] **********\n",
      "\n",
      "1. Accuarcy: 0.7166968053044003\n",
      "\n",
      "2. The F-1 score of the model 0.7681817848482283\n",
      "\n",
      "3. The recall score of the model 0.7166968053044003\n",
      "\n",
      "4. Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.08      0.21      0.12       293\n",
      "          1       0.91      0.77      0.83      3025\n",
      "\n",
      "avg / total       0.84      0.72      0.77      3318\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  62  231]\n",
      " [ 709 2316]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [KNN] **********\n",
      "\n",
      "1. Accuarcy: 0.9017480409885473\n",
      "\n",
      "2. The F-1 score of the model 0.8767342282914381\n",
      "\n",
      "3. The recall score of the model 0.9017480409885473\n",
      "\n",
      "4. Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.31      0.09      0.14       293\n",
      "          1       0.92      0.98      0.95      3025\n",
      "\n",
      "avg / total       0.86      0.90      0.88      3318\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  27  266]\n",
      " [  60 2965]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [Random Forest] **********\n",
      "\n",
      "1. Accuarcy: 0.9113924050632911\n",
      "\n",
      "2. The F-1 score of the model 0.8831823179498747\n",
      "\n",
      "3. The recall score of the model 0.9113924050632911\n",
      "\n",
      "4. Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.49      0.10      0.16       293\n",
      "          1       0.92      0.99      0.95      3025\n",
      "\n",
      "avg / total       0.88      0.91      0.88      3318\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  28  265]\n",
      " [  29 2996]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = SVC(kernel = 'linear') \n",
    "clf3 = GaussianNB()\n",
    "clf4 = KNeighborsClassifier()\n",
    "clf5 = RandomForestClassifier(random_state=1)\n",
    "clf6 = GradientBoostingClassifier()\n",
    "\n",
    "labels = ['Logistic Regression', 'Linear SVM', 'Naive Bayes', 'KNN', 'Random Forest', 'GradientBoosting', ]\n",
    "\n",
    "%time \n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6], labels):\n",
    "    clf.fit(count_vect_train1, y_train)\n",
    "    y_pred_clf = clf.predict(count_vect_test1)\n",
    "    cm = confusion_matrix(y_test, y_pred_clf)\n",
    "    \n",
    "    print('\\n********** [{}] **********\\n'.format(label))\n",
    "    print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "    print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "    print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "    print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "        classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
