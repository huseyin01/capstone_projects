{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The data set obtained from below url:\n",
    "'http://seotest.ciberius.info/seo--jmcauley.ucsd.edu/data/amazon/'\n",
    "\n",
    "Data Format:\n",
    "\n",
    "product/productId: asin, e.g. amazon.com/dp/B00006HAXW\n",
    "product/title: title of the product\n",
    "product/price: price of the product\n",
    "review/userId: id of the user, e.g. A1RSDE90N6RSZF\n",
    "review/profileName: name of the user\n",
    "review/helpfulness: fraction of users who found the review helpful\n",
    "review/score: rating of the product\n",
    "review/time: time of the review (unix time)\n",
    "review/summary: review summary\n",
    "review/text: text of the review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "df = getDF('data_capstone_2/reviews_Patio_Lawn_and_Garden_5.json.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>Carter H \"1amazonreviewer@gmail . com\"</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Good USA company that stands behind their prod...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great Hoses</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>06 21, 2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                            reviewerName helpful  \\\n",
       "0  A1JZFGZEZVWQPY  B00002N674  Carter H \"1amazonreviewer@gmail . com\"  [4, 4]   \n",
       "\n",
       "                                          reviewText  overall      summary  \\\n",
       "0  Good USA company that stands behind their prod...      4.0  Great Hoses   \n",
       "\n",
       "   unixReviewTime   reviewTime  \n",
       "0      1308614400  06 21, 2011  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Information about the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13272 entries, 0 to 13271\n",
      "Data columns (total 9 columns):\n",
      "reviewerID        13272 non-null object\n",
      "asin              13272 non-null object\n",
      "reviewerName      13107 non-null object\n",
      "helpful           13272 non-null object\n",
      "reviewText        13272 non-null object\n",
      "overall           13272 non-null float64\n",
      "summary           13272 non-null object\n",
      "unixReviewTime    13272 non-null int64\n",
      "reviewTime        13272 non-null object\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 1.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we learned from the information:\n",
    "\n",
    "    * We have the shape, 13272 observations(records or rows) and 9 columns (or variables).\n",
    "    * There is no missing value.\n",
    "    * There are two variables related with date but data types are not datetime, one of them is \"int64\" and the other one is \"object\". One time related variable will be enough for us, we can drop one of them.\n",
    "    * We need to figure out that whether the \"helpful\" variable needs to be converted to numeric type in order to use it.\n",
    "    * There are two different variables which identify reviewer/user, we can drop one of them.\n",
    "    * In order to improve practical and readable coding, we need change some of the column names and also we need to convert column names to lowercase.\n",
    "    \n",
    "            - \"reviewerID\"    -->   \"customer\"\n",
    "            - \"asin\"          -->   \"product\"\n",
    "            - \"reviewerName\"  -->   column will be droped \n",
    "            - \"reviewText\"    -->   \"review_text\" (will be \n",
    "            - \"helpful\"       -->   will be splited in two columns; \"pos_feedback\" as positive feedback + \"neg_feedback\" as  negative feedback. \n",
    "            - \"overall\"       -->   \"rating\"\n",
    "            - \"summary\"       -->   as is \n",
    "            - \"unixReviewTime\"-->   \"time\"    \n",
    "            - \"reviewTime\"    -->   column will be droped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing learned issues\n",
    "\n",
    "    * Creating the new columns. \n",
    "    * Dropping redundant columns\n",
    "    * Changing some column names and making lowercase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating 3 new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>Carter H \"1amazonreviewer@gmail . com\"</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Good USA company that stands behind their prod...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Great Hoses</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>06 21, 2011</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Great Hoses Good USA company that stands behin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                            reviewerName helpful  \\\n",
       "0  A1JZFGZEZVWQPY  B00002N674  Carter H \"1amazonreviewer@gmail . com\"  [4, 4]   \n",
       "\n",
       "                                          reviewText  overall      summary  \\\n",
       "0  Good USA company that stands behind their prod...      4.0  Great Hoses   \n",
       "\n",
       "   unixReviewTime   reviewTime  pos_feedback  neg_feedback  \\\n",
       "0      1308614400  06 21, 2011             4             0   \n",
       "\n",
       "                                         review_text  \n",
       "0  Great Hoses Good USA company that stands behin...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will create two new columns from the \"helpful\" column in order to make computation easier\n",
    "\n",
    "list1=[]\n",
    "list2=[]\n",
    "for item in df['helpful']:\n",
    "    list1.append(item[0])\n",
    "    list2.append(item[1]-item[0])\n",
    "        \n",
    "# 1st new column\n",
    "df['pos_feedback'] = list1\n",
    "\n",
    "# 2nd new column\n",
    "df['neg_feedback'] = list2\n",
    "\n",
    "# 3rd new column: will be joint text of review and summary columns.\n",
    "df['review_text'] = df[['summary', 'reviewText']].apply(\n",
    "    lambda x: ' '.join(str(y) for y in x if str(y) !='nan'), axis=1)\n",
    "\n",
    "df.head(1)\n",
    "\n",
    "# Number of columns increased to 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping redundant 3 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>overall</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Great Hoses Good USA company that stands behin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin  overall  unixReviewTime  pos_feedback  \\\n",
       "0  A1JZFGZEZVWQPY  B00002N674      4.0      1308614400             4   \n",
       "\n",
       "   neg_feedback                                        review_text  \n",
       "0             0  Great Hoses Good USA company that stands behin...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will drop the \"reviewerName\" since we have \"reviewerID\" as enough for identifing the reviewer/customer\n",
    "# And also we will drop the \"reviewTime\" column as we have another date column (\"unixReviewTime\")\n",
    "\n",
    "df=df.drop(['reviewerName', 'reviewText', 'reviewTime', 'summary', 'helpful'], axis=1)\n",
    "df.head(1)\n",
    "\n",
    "# Now we have 8 columns remained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Great Hoses Good USA company that stands behin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         customer     product  rating        time  pos_feedback  neg_feedback  \\\n",
       "0  A1JZFGZEZVWQPY  B00002N674     4.0  1308614400             4             0   \n",
       "\n",
       "                                         review_text  \n",
       "0  Great Hoses Good USA company that stands behin...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['customer', 'product', 'rating', 'time', 'pos_feedback', 'neg_feedback', 'review_text']\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descriptive statistics summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13272.000000</td>\n",
       "      <td>1.327200e+04</td>\n",
       "      <td>13272.000000</td>\n",
       "      <td>13272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.186483</td>\n",
       "      <td>1.358624e+09</td>\n",
       "      <td>3.233424</td>\n",
       "      <td>0.523282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.084114</td>\n",
       "      <td>4.709839e+07</td>\n",
       "      <td>20.279594</td>\n",
       "      <td>2.765096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.548928e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.341965e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.370304e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.393546e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.405987e+09</td>\n",
       "      <td>923.000000</td>\n",
       "      <td>167.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating          time  pos_feedback  neg_feedback\n",
       "count  13272.000000  1.327200e+04  13272.000000  13272.000000\n",
       "mean       4.186483  1.358624e+09      3.233424      0.523282\n",
       "std        1.084114  4.709839e+07     20.279594      2.765096\n",
       "min        1.000000  9.548928e+08      0.000000      0.000000\n",
       "25%        4.000000  1.341965e+09      0.000000      0.000000\n",
       "50%        5.000000  1.370304e+09      0.000000      0.000000\n",
       "75%        5.000000  1.393546e+09      1.000000      0.000000\n",
       "max        5.000000  1.405987e+09    923.000000    167.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can use \".describe()\" method to get the statistics summary of numeric variables.\n",
    "\n",
    "df.describe()\n",
    "\n",
    "# We got statistics of 4 variables as we have 4 numeric variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics of non-numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of unique customers: 1686\n",
      "\n",
      "Number of unique products: 962\n",
      "\n",
      "Review per customer: 7.871886120996441\n",
      "\n",
      "Review per product: 13.796257796257796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Although they are not numeric we can produce statistics from non-numeric variables\n",
    "\n",
    "print('\\nNumber of unique customers: {}\\n\\nNumber of unique products: {}'.\n",
    "      format(len(df['customer'].unique()), len(df['product'].unique())))\n",
    "\n",
    "print('\\nReview per customer: {}\\n\\nReview per product: {}\\n'.\n",
    "         format((len(df)/len(df['customer'].unique())), (len(df)/len(df['product'].unique()))))\n",
    "\n",
    "# We produced 4 additional statistics with non-numeric variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What we learned from the statistics summary\n",
    "\n",
    "    * Rating:\n",
    "      - Mean of the ratings is more than 4 out of 5. It means that people are tendentious to giving high ratings. \"std\" value (1.084) and percentile values show that 1 and 2 star ratings are rare. \n",
    "      - Small numbers of \"ratings under 4\" will decrease the predictability of these ratings. To overcome this problem we need to split the ratings in to two groups as \"good\" and \"bad\" ratings.\n",
    "\n",
    "    * total votes (t_votes) and positive votes (p_votes):\n",
    "      - Their means are more than 3.0 but percentile values shows that more than half of the reviews don't have \"helpful\"votes.\n",
    "      - They have outliers and should be cleaned or imputed. \n",
    "\n",
    "    * Non-numeric variables statistics:\n",
    "      - Some customers have more than one ratings and most probably we have some outliers.\n",
    "      - All ratings do not belong to diffent different people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import contractions\n",
    "\n",
    "#nlp = spacy.load('en_core', parse=True, tag=True, entity=True)\n",
    "\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "                                              \n",
    "def normalize_corpus(text, lowercase=True, remove_stop_words=True, remove_url=True):\n",
    "    \n",
    "    \"\"\"[1] Lowercase the text \n",
    "       [2] Keep only words \n",
    "       [3] Find URLs \n",
    "       [4] Remove links from posts \n",
    "       [5] Expending contractions \n",
    "       [6] Removing whitespace \n",
    "       [7] Remove apostrophe sign  \n",
    "       [8] Remove stopwords and Stemming\"\"\"\n",
    "    \n",
    "    # Creating stopwordlist and editing \n",
    "    stopword_list= stopwords.words('english')\n",
    "    \n",
    "    # \"no\" and \"not\" may give us information so those are removed from stop lists\n",
    "    stopword_list.remove('no') \n",
    "    stopword_list.remove('not')\n",
    "    \n",
    "    ##[1] Lowercase the text\n",
    "    if (lowercase==True):\n",
    "        text = str(text).lower()\n",
    "    \n",
    "    ##[2] Keeping only words\n",
    "    text = re.sub(r'[^a-zA-Z]',r' ', text)\n",
    "    \n",
    "    ##[3] Find URLs\n",
    "    global URLs\n",
    "    URLs = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+])+', text)\n",
    "    #URLs = re.findall('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', text)\n",
    "    \n",
    "    ##[4] Removing Links \n",
    "    text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', r'', text)\n",
    "    \n",
    "    ##[5] Expending contractions such as I'm, you're into I am, you are\n",
    "    text = contractions.fix(text)\n",
    "     \n",
    "    ##[6] Removing whitespace\n",
    "    text = re.sub(r'nbsp', r'', text)\n",
    "        \n",
    "    ##[7] Removing ' (apostrophe) sign\n",
    "    text = re.sub(r\"'\", r'', text)\n",
    "      \n",
    "    ##[8] Removing stopwords and Lemmatization\n",
    "    if (remove_stop_words==True):\n",
    "        \n",
    "        text = \" \".join([lemmatizer.lemmatize(w) for w in text.split(' ') if w not in stopword_list])\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        text = \" \".join([lemmatizer.lemmatize(w) for w in text.split(' ')])\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download(\"wordnet\", \"C:\\Users\\Mike/nltk_data/\")\n",
    "df['clean_text'] = df['review_text'].map(lambda text: normalize_corpus(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of raw tokens: 2438779\n",
      "Number of clean tokens: 1096586\n",
      "\n",
      "Percentage of removed tokens: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Let's put aside number of raw tokens in order to measure of cleaned tokens\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "raw_tokens=len([w for t in (df[\"review_text\"].apply(word_tokenize)) for w in t])\n",
    "print('Number of raw tokens: {}'.format(raw_tokens))\n",
    "clean_tokens=len([w for t in (df[\"clean_text\"].apply(word_tokenize)) for w in t])\n",
    "print('Number of clean tokens: {}\\n'.format(clean_tokens))\n",
    "print('Percentage of removed tokens: {0:.2f}'.format(1-(clean_tokens/raw_tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('nlp_reviews_cleaned_2.csv', sep=',', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "\n",
    "## Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, roc_curve, auc, \\\n",
    "            classification_report, recall_score, precision_recall_curve\n",
    "\n",
    "import contractions\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    12080\n",
      "0     1192\n",
      "Name: rating_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df['rating_class'] = df['rating'].apply(lambda x: 0 if x <= 2 else 1)\n",
    "print(df.rating_class.value_counts())\n",
    "df_train = df[0:10000]\n",
    "X_1 = df_train['clean_text']\n",
    "y_1 = df_train['rating_class']\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_1, y_1, test_size=0.25, random_state=5)\n",
    "\n",
    "cv1 = CountVectorizer(ngram_range=(1,1))\n",
    "cv_train1 = cv1.fit_transform(X_train1)\n",
    "cv_train1 = cv_train1.toarray()\n",
    "cv_test1 = cv1.transform(X_test1)\n",
    "cv_test1 = cv_test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Scores\n",
      "\n",
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.894\n",
      "\n",
      "2. The F-1 score of the model 0.8866035219097399\n",
      "\n",
      "3. The recall score of the model 0.894\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.31      0.36       237\n",
      "           1       0.93      0.96      0.94      2263\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      2500\n",
      "   macro avg       0.67      0.63      0.65      2500\n",
      "weighted avg       0.88      0.89      0.89      2500\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  73  164]\n",
      " [ 101 2162]]\n",
      "\n",
      "\n",
      "\n",
      "********** [Linear SVM] **********\n",
      "\n",
      "1. Accuarcy: 0.884\n",
      "\n",
      "2. The F-1 score of the model 0.8844340509161163\n",
      "\n",
      "3. The recall score of the model 0.884\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.40      0.39       237\n",
      "           1       0.94      0.94      0.94      2263\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      2500\n",
      "   macro avg       0.66      0.67      0.66      2500\n",
      "weighted avg       0.88      0.88      0.88      2500\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  94  143]\n",
      " [ 147 2116]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = SVC(kernel = 'linear')\n",
    "\n",
    "labels = ['Logistic Regression', 'Linear SVM']\n",
    "print('Initial Scores\\n\\n')\n",
    "\n",
    "for clf, label in zip([clf1, clf2], labels):\n",
    "    clf.fit(cv_train1, y_train1)\n",
    "    y_pred_clf = clf.predict(cv_test1)\n",
    "    cm = confusion_matrix(y_test1, y_pred_clf)\n",
    "    \n",
    "    print('********** [{}] **********\\n'.format(label))\n",
    "    print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test1, y_pred_clf)))\n",
    "    print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test1, y_pred_clf, average='weighted')))\n",
    "    print('3. The recall score of the model {}\\n'.format(recall_score(y_test1, y_pred_clf, average='weighted')))\n",
    "    print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format\n",
    "          (classification_report(y_test1, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
