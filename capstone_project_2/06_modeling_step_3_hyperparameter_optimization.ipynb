{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "## Regular Expression\n",
    "import re\n",
    "\n",
    "## Arrays\n",
    "import numpy as np\n",
    "\n",
    "## DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "## Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import contractions\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    10421\n",
      "0     2851\n",
      "Name: rating_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#reading the data\n",
    "df=pd.read_csv('data_capstone_2/nlp_reviews_cleaned.csv', delimiter=',')\n",
    "\n",
    "#creating the classes\n",
    "df['rating_class'] = df['rating'].apply(lambda x: 0 if x <= 3 else 1)\n",
    "print(df.rating_class.value_counts())\n",
    "\n",
    "#train data set reduced due to capacity of computing\n",
    "df_train = df[0:10000]\n",
    "\n",
    "#splitting data set into train and test sets\n",
    "X = df_train['clean_text']\n",
    "y = df_train['rating_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inital Scores with best Vectorizer (CountVectorizer) and best n-gram (unigram) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word vector with CountVectorizer\n",
    "\n",
    "count_vect1 = CountVectorizer(ngram_range=(1,1))\n",
    "count_vect_train1 = count_vect1.fit_transform(X_train)\n",
    "count_vect_train1 = count_vect_train1.toarray()\n",
    "count_vect_test1 = count_vect1.transform(X_test)\n",
    "count_vect_test1 = count_vect_test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.824\n",
      "\n",
      "2. The F-1 score of the model 0.8162350712701556\n",
      "\n",
      "3. The recall score of the model 0.824\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.51      0.57       567\n",
      "           1       0.86      0.92      0.89      1933\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      2500\n",
      "   macro avg       0.75      0.71      0.73      2500\n",
      "weighted avg       0.81      0.82      0.82      2500\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 287  280]\n",
      " [ 160 1773]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the scores with the best vector (according to step1 and step2)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "\n",
    "labels = ['Logistic Regression']\n",
    "for clf, label in zip([clf1], labels):\n",
    "    clf.fit(count_vect_train1, y_train)\n",
    "    y_pred_clf = clf.predict(count_vect_test1)\n",
    "    cm = confusion_matrix(y_test, y_pred_clf)\n",
    "    \n",
    "    print('\\n********** [{}] **********\\n'.format(label))\n",
    "    print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "    print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "    print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "    print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "        classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [Linear SVM] **********\n",
      "\n",
      "1. Accuarcy: 0.8084\n",
      "\n",
      "2. The F-1 score of the model 0.80554359794688\n",
      "\n",
      "3. The recall score of the model 0.8084\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.54      0.56       567\n",
      "           1       0.87      0.89      0.88      1933\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      2500\n",
      "   macro avg       0.73      0.71      0.72      2500\n",
      "weighted avg       0.80      0.81      0.81      2500\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 305  262]\n",
      " [ 217 1716]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf2 = SVC(kernel = 'linear')\n",
    "\n",
    "labels = ['Linear SVM']\n",
    "for clf, label in zip([clf2], labels):\n",
    "    clf.fit(count_vect_train1, y_train)\n",
    "    y_pred_clf2 = clf.predict(count_vect_test1)\n",
    "    cm = confusion_matrix(y_test, y_pred_clf2)\n",
    "    \n",
    "    print('\\n********** [{}] **********\\n'.format(label))\n",
    "    print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf2)))\n",
    "    print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf2, average='weighted')))\n",
    "    print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf2, average='weighted')))\n",
    "    print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "        classification_report(y_test, y_pred_clf2), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  vectorizer   model  accuracy    class  precision    recall  f1-score  \\\n",
      "0  CountVect  LogReg    0.8240      bad   0.642058  0.506173  0.566075   \n",
      "1  CountVect  LogReg    0.8240  not bad   0.863614  0.917227  0.889614   \n",
      "0  CountVect     SVM    0.8084      bad   0.584291  0.537919  0.560147   \n",
      "1  CountVect     SVM    0.8084  not bad   0.867543  0.887739  0.877525   \n",
      "\n",
      "   support  \n",
      "0    567.0  \n",
      "1   1933.0  \n",
      "0    567.0  \n",
      "1   1933.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "\n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-1] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T\n",
    "\n",
    "\n",
    "def comparison_matrix(y_test, y_pred, label, vector):\n",
    "    df = pandas_classification_report(y_test, y_pred)\n",
    "    df = df[:2]\n",
    "    df['class']=['bad', 'not bad']\n",
    "    df['accuracy']= metrics.accuracy_score(y_test, y_pred)\n",
    "    df['model'] = label\n",
    "    df['vectorizer'] = vector\n",
    "    df = df[['vectorizer', 'model', 'accuracy', 'class', 'precision', 'recall', 'f1-score', 'support']]\n",
    "    return df\n",
    "\n",
    "frames = []\n",
    "y_preds = [y_pred_clf, y_pred_clf2]\n",
    "labels = ['LogReg', 'SVM']\n",
    "vector = 'CountVect'\n",
    "for y_pred, label in zip(y_preds, labels):\n",
    "    df = comparison_matrix(y_test, y_pred, label, vector)\n",
    "    frames.append(df)\n",
    "\n",
    "result = pd.concat(frames)\n",
    "\n",
    "result1 = result.set_index(['vectorizer', 'model', 'accuracy', 'class'])\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "vectorizer model  accuracy class                                          \n",
      "CountVect  LogReg 0.8240   bad       0.642058  0.506173  0.566075    567.0\n",
      "                           not bad   0.863614  0.917227  0.889614   1933.0\n",
      "           SVM    0.8084   bad       0.584291  0.537919  0.560147    567.0\n",
      "                           not bad   0.867543  0.887739  0.877525   1933.0\n"
     ]
    }
   ],
   "source": [
    "print(result.set_index(['vectorizer', 'model', 'accuracy', 'class']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    precision    recall  f1-score  support\n",
      "vectorizer model  accuracy class                                          \n",
      "CountVect  LogReg 0.8240   bad       0.642058  0.506173  0.566075    567.0\n",
      "                           not bad   0.863614  0.917227  0.889614   1933.0\n",
      "           SVM    0.8084   bad       0.584291  0.537919  0.560147    567.0\n",
      "                           not bad   0.867543  0.887739  0.877525   1933.0\n"
     ]
    }
   ],
   "source": [
    "result1 = result.set_index(['vectorizer', 'model', 'accuracy', 'class'])\n",
    "print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_class_report_logreg_cv = df_class_report_logreg_cv[['class', 'precision', 'recall', 'f1-score', 'support']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   accuracy    class  precision    recall  f1-score  support\n",
      "0     0.824      Bad   0.642058  0.506173  0.566075    567.0\n",
      "1     0.824  Not bad   0.863614  0.917227  0.889614   1933.0\n"
     ]
    }
   ],
   "source": [
    "df_class_report_logreg_cv = pandas_classification_report(y_true=y_test, y_pred=y_pred_clf)\n",
    "df_class_report_logreg_cv = df_class_report_logreg_cv[:2]\n",
    "df_class_report_logreg_cv['class']=['Bad', 'Not bad']\n",
    "df_class_report_logreg_cv['accuracy']= metrics.accuracy_score(y_test, y_pred_clf)\n",
    "df_class_report_logreg_cv = df_class_report_logreg_cv[\n",
    "    ['accuracy', 'class', 'precision', 'recall', 'f1-score', 'support']]\n",
    "print(df_class_report_logreg_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  vectorizer   model  accuracy    class  precision    recall  f1-score  \\\n",
      "0  CountVect  LogReg    0.8240      Bad   0.642058  0.506173  0.566075   \n",
      "1  CountVect  LogReg    0.8240  Not bad   0.863614  0.917227  0.889614   \n",
      "0  CountVect     SVM    0.8084      Bad   0.584291  0.537919  0.560147   \n",
      "1  CountVect     SVM    0.8084  Not bad   0.867543  0.887739  0.877525   \n",
      "\n",
      "   support  \n",
      "0    567.0  \n",
      "1   1933.0  \n",
      "0    567.0  \n",
      "1   1933.0  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"for item in models:\\n    df = \\ndf_svm = comparison_matrix(y_test, y_pred_clf2, 'SVM', 'CountVect')\\ndf_log = comparison_matrix(y_test, y_pred_clf, 'LogReg', 'CountVect')\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = []\n",
    "y_preds = [y_pred_clf, y_pred_clf2]\n",
    "labels = ['LogReg', 'SVM']\n",
    "vector = 'CountVect'\n",
    "for y_pred, label in zip(y_preds, labels):\n",
    "    df = comparison_matrix(y_test, y_pred, label, vector)\n",
    "    frames.append(df)\n",
    "\n",
    "result = pd.concat(frames)\n",
    "print(result)\n",
    "'''for item in models:\n",
    "    df = \n",
    "df_svm = comparison_matrix(y_test, y_pred_clf2, 'SVM', 'CountVect')\n",
    "df_log = comparison_matrix(y_test, y_pred_clf, 'LogReg', 'CountVect')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_svm, df_log]\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   accuracy    class  precision    recall  f1-score  support\n",
      "vectorizer model                                                            \n",
      "CountVect  SVM       0.8084      Bad   0.584291  0.537919  0.560147    567.0\n",
      "           SVM       0.8084  Not bad   0.867543  0.887739  0.877525   1933.0\n",
      "           LogReg    0.8240      Bad   0.642058  0.506173  0.566075    567.0\n",
      "           LogReg    0.8240  Not bad   0.863614  0.917227  0.889614   1933.0\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "print(result.set_index(['vectorizer', 'model', 'accuracy']))\n",
    "df10 = result.groupby(['vectorizer', 'class'])['f1-score'].max()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "#X = iris.data\n",
    "#y = iris.target\n",
    "\n",
    "# Binarize the output\n",
    "y = label_binarize(y_test, classes=[0, 1])\n",
    "n_classes = y.shape[1]\n",
    "\n",
    "# Add noisy features to make the problem harder\n",
    "random_state = np.random.RandomState(0)\n",
    "n_samples, n_features = X.shape\n",
    "X = np.c_[X, random_state.randn(n_samples, 200 * n_features)]\n",
    "\n",
    "# shuffle and split training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.5,\n",
    "                                                    random_state=0)\n",
    "\n",
    "# Learn to predict each class against the other\n",
    "classifier = OneVsRestClassifier(svm.SVC(kernel='linear', probability=True,\n",
    "                                 random_state=random_state))\n",
    "y_score = classifier.fit(X_train, y_train).decision_function(X_test)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.822\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def roc_cur(X_test, y_test):\n",
    "    probs = clf.predict_proba(X_test)\n",
    "    probs = probs[:, 1]\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, probs)\n",
    "    pyplot.plot([0, 1], [0, 1], linestyle='--')\n",
    "    pyplot.plot(fpr, tpr, marker='.')\n",
    "    pyplot.showauc_score = roc_auc_score(y_test, probs)\n",
    "    print('AUC: %.3f' % auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can only tuple-index with a MultiIndex",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-157c0b773a62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    909\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 911\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_values_tuple\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Can only tuple-index with a MultiIndex'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0;31m# If key is contained, would have returned by now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can only tuple-index with a MultiIndex"
     ]
    }
   ],
   "source": [
    "y_score = clf.fit(count_vect_train1, y_train).decision_function(count_vect_test1)\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_clf)\n",
    "auc = metrics.roc_auc_score(y_test, y_pred_clf)\n",
    "plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(y_train, y_train_prob, y_test, y_test_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.9\n",
      "\n",
      "2. The F-1 score of the model 0.8866628460110704\n",
      "\n",
      "3. The recall score of the model 0.9\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.25      0.32       118\n",
      "           1       0.92      0.97      0.95      1132\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1250\n",
      "   macro avg       0.69      0.61      0.63      1250\n",
      "weighted avg       0.88      0.90      0.89      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  29   89]\n",
      " [  36 1096]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [Linear SVM] **********\n",
      "\n",
      "1. Accuarcy: 0.8928\n",
      "\n",
      "2. The F-1 score of the model 0.8883063890510475\n",
      "\n",
      "3. The recall score of the model 0.8928\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      0.35      0.38       118\n",
      "           1       0.93      0.95      0.94      1132\n",
      "\n",
      "   micro avg       0.89      0.89      0.89      1250\n",
      "   macro avg       0.68      0.65      0.66      1250\n",
      "weighted avg       0.88      0.89      0.89      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  41   77]\n",
      " [  57 1075]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [Naive Bayes] **********\n",
      "\n",
      "1. Accuarcy: 0.8048\n",
      "\n",
      "2. The F-1 score of the model 0.8166696388402489\n",
      "\n",
      "3. The recall score of the model 0.8048\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.13      0.11       118\n",
      "           1       0.91      0.88      0.89      1132\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      1250\n",
      "   macro avg       0.50      0.50      0.50      1250\n",
      "weighted avg       0.83      0.80      0.82      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 15 103]\n",
      " [141 991]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [KNN] **********\n",
      "\n",
      "1. Accuarcy: 0.8824\n",
      "\n",
      "2. The F-1 score of the model 0.8537033028406354\n",
      "\n",
      "3. The recall score of the model 0.8824\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.03      0.05       118\n",
      "           1       0.91      0.97      0.94      1132\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1250\n",
      "   macro avg       0.51      0.50      0.49      1250\n",
      "weighted avg       0.83      0.88      0.85      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[   4  114]\n",
      " [  33 1099]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [Random Forest] **********\n",
      "\n",
      "1. Accuarcy: 0.904\n",
      "\n",
      "2. The F-1 score of the model 0.8695320018672488\n",
      "\n",
      "3. The recall score of the model 0.904\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.06      0.10       118\n",
      "           1       0.91      0.99      0.95      1132\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1250\n",
      "   macro avg       0.67      0.53      0.53      1250\n",
      "weighted avg       0.87      0.90      0.87      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[   7  111]\n",
      " [   9 1123]]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "********** [GradientBoosting] **********\n",
      "\n",
      "1. Accuarcy: 0.9048\n",
      "\n",
      "2. The F-1 score of the model 0.873538345841751\n",
      "\n",
      "3. The recall score of the model 0.9048\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.08      0.14       118\n",
      "           1       0.91      0.99      0.95      1132\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1250\n",
      "   macro avg       0.69      0.54      0.55      1250\n",
      "weighted avg       0.87      0.90      0.87      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  10  108]\n",
      " [  11 1121]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the scores with the best vector (according to step1 and step2)\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = SVC(kernel = 'linear') \n",
    "clf3 = GaussianNB()\n",
    "clf4 = KNeighborsClassifier()\n",
    "clf5 = RandomForestClassifier(random_state=1)\n",
    "clf6 = GradientBoostingClassifier()\n",
    "\n",
    "labels = ['Logistic Regression', 'Linear SVM', 'Naive Bayes', 'KNN', 'Random Forest', 'GradientBoosting', ]\n",
    "for clf, label in zip([clf1, clf2, clf3, clf4, clf5, clf6], labels):\n",
    "    clf.fit(count_vect_train1, y_train)\n",
    "    y_pred_clf = clf.predict(count_vect_test1)\n",
    "    cm = confusion_matrix(y_test, y_pred_clf)\n",
    "    \n",
    "    print('\\n********** [{}] **********\\n'.format(label))\n",
    "    print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "    print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "    print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "    print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "        classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Logisric Regression - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** Logistic Regression **********\n",
      "\n",
      "Tuned Logistic Regression Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Best score is 0.9189333333333334\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2500, 1250]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-9018467e90c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Tuned Logistic Regression Parameters: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best score is {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogreg_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'1. Accuarcy: {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_clf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'2. The F-1 score of the model {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'3. The recall score of the model {}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2500, 1250]"
     ]
    }
   ],
   "source": [
    "# define the paramater spaces\n",
    "params = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000], 'penalty': ['l1', 'l2']}\n",
    "# Instantiate a logistic regression classifier: logreg\n",
    "logreg = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, params, cv=5)\n",
    "# Fit it to the data\n",
    "logreg_cv.fit(count_vect_train1, y_train)\n",
    "# Print the tuned parameters and score\n",
    "\n",
    "print('\\n********** Logistic Regression **********\\n')\n",
    "print(\"Tuned Logistic Regression Parameters: {}\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\".format(logreg_cv.best_score_))\n",
    "print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "    classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Logisric Regression - Modeling with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.9064\n",
      "\n",
      "2. The F-1 score of the model 0.8817491157291112\n",
      "\n",
      "3. The recall score of the model 0.9064\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.14      0.23       118\n",
      "           1       0.92      0.99      0.95      1132\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1250\n",
      "   macro avg       0.72      0.56      0.59      1250\n",
      "weighted avg       0.88      0.91      0.88      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[  17  101]\n",
      " [  16 1116]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = 'Logistic Regression'\n",
    "clf = LogisticRegression(C=0.1, penalty='l2')\n",
    "\n",
    "clf.fit(count_vect_train1, y_train)\n",
    "y_pred_clf = clf.predict(count_vect_test1)\n",
    "cm = confusion_matrix(y_test, y_pred_clf)\n",
    "    \n",
    "print('\\n********** [{}] **********\\n'.format(label))\n",
    "print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "    classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Logisric Regression - Modeling with Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.9685333333333334\n",
      "\n",
      "2. The F-1 score of the model 0.9652290559106603\n",
      "\n",
      "3. The recall score of the model 0.9685333333333334\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.63      0.77       319\n",
      "           1       0.97      1.00      0.98      3431\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      3750\n",
      "   macro avg       0.98      0.82      0.88      3750\n",
      "weighted avg       0.97      0.97      0.97      3750\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 201  118]\n",
      " [   0 3431]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = 'Logistic Regression'\n",
    "clf = LogisticRegression(C=0.1, penalty='l2')\n",
    "\n",
    "clf.fit(count_vect_train1, y_train)\n",
    "y_pred_clf = clf.predict(count_vect_train1)\n",
    "cm = confusion_matrix(y_train, y_pred_clf)\n",
    "    \n",
    "print('\\n********** [{}] **********\\n'.format(label))\n",
    "print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_train, y_pred_clf)))\n",
    "print('2. The F-1 score of the model {}\\n'.format(f1_score(y_train, y_pred_clf, average='weighted')))\n",
    "print('3. The recall score of the model {}\\n'.format(recall_score(y_train, y_pred_clf, average='weighted')))\n",
    "print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "    classification_report(y_train, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Logisric Regression - Hyperparameter Tuning Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution of Hyperparameter tuning (on Test Set): - 0.05 % "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Linear SVM - Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9056\n",
      "Tuned Model Parameters: {'C': 0.001, 'gamma': 0.001}\n"
     ]
    }
   ],
   "source": [
    "# Specify the hyperparameter space\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "param_grid = {'C': Cs, 'gamma' : gammas}\n",
    "svm=SVC(kernel='linear')\n",
    "svm_cv = GridSearchCV(svm, param_grid, cv=5)\n",
    "\n",
    "# Fit to the training set\n",
    "svm_cv.fit(count_vect_train1, y_train)\n",
    "\n",
    "# Compute and print metrics\n",
    "print(\"Accuracy: {}\".format(svm_cv.score(count_vect_test1, y_test)))\n",
    "print(\"Tuned Model Parameters: {}\".format(svm_cv.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Linear SVM (Tuned) - Modeling with Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [Logistic Regression] **********\n",
      "\n",
      "1. Accuarcy: 0.9056\n",
      "\n",
      "2. The F-1 score of the model 0.8607382031905961\n",
      "\n",
      "3. The recall score of the model 0.9056\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       118\n",
      "           1       0.91      1.00      0.95      1132\n",
      "\n",
      "   micro avg       0.91      0.91      0.91      1250\n",
      "   macro avg       0.45      0.50      0.48      1250\n",
      "weighted avg       0.82      0.91      0.86      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[   0  118]\n",
      " [   0 1132]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label = 'Logistic Regression'\n",
    "clf = SVC(kernel='linear', C=0.001, gamma=0.001)\n",
    "\n",
    "clf.fit(count_vect_train1, y_train)\n",
    "y_pred_clf = clf.predict(count_vect_test1)\n",
    "cm = confusion_matrix(y_test, y_pred_clf)\n",
    "    \n",
    "print('\\n********** [{}] **********\\n'.format(label))\n",
    "print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "    classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computations for other models delayed due to limitations of capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/onlyone/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 6 candidates, totalling 12 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  12 | elapsed:   20.5s remaining:   14.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 out of  12 | elapsed:   24.4s remaining:    8.1s\n",
      "[Parallel(n_jobs=-1)]: Done  12 out of  12 | elapsed:   24.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9149333333333334\n",
      "Tuned Model Parameters: {'nb__alpha': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
    "\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('nb', nb_model)])\n",
    "\n",
    "# parameter grid\n",
    "param_grid = {'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator=clf, param_grid=param_grid,\n",
    "                     verbose=10, n_jobs=-1, iid=True, refit=True, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(count_vect_train1, y_train)  # we can use the full data here but im only using xtrain. \n",
    "\n",
    "print(\"Accuracy: {}\".format(model.score(count_vect_train1, y_train)))\n",
    "print(\"Tuned Model Parameters: {}\".format(model.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** MultinomialNB on train set **********\n",
      "\n",
      "1. Accuarcy: 0.9546666666666667\n",
      "\n",
      "2. The F-1 score of the model 0.9480687114894255\n",
      "\n",
      "3. The recall score of the model 0.9546666666666667\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.50      0.65       319\n",
      "           1       0.96      1.00      0.98      3431\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3750\n",
      "   macro avg       0.95      0.75      0.81      3750\n",
      "weighted avg       0.95      0.95      0.95      3750\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[ 158  161]\n",
      " [   9 3422]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_nb = MultinomialNB(alpha = 10)\n",
    "\n",
    "clf_nb.fit(count_vect_train1, y_train)\n",
    "y_pred_clf = clf.predict(count_vect_train1)\n",
    "cm = confusion_matrix(y_train, y_pred_clf)\n",
    "    \n",
    "print('\\n********** MultinomialNB on train set **********\\n')\n",
    "print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_train, y_pred_clf)))\n",
    "print('2. The F-1 score of the model {}\\n'.format(f1_score(y_train, y_pred_clf, average='weighted')))\n",
    "print('3. The recall score of the model {}\\n'.format(recall_score(y_train, y_pred_clf, average='weighted')))\n",
    "print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "    classification_report(y_train, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "********** [MultinomialNB] **********\n",
      "\n",
      "1. Accuarcy: 0.9048\n",
      "\n",
      "2. The F-1 score of the model 0.8633327710340627\n",
      "\n",
      "3. The recall score of the model 0.9048\n",
      "\n",
      "4. Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.02      0.03       118\n",
      "           1       0.91      1.00      0.95      1132\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1250\n",
      "   macro avg       0.65      0.51      0.49      1250\n",
      "weighted avg       0.86      0.90      0.86      1250\n",
      "\n",
      "5. Confusion matrix:\n",
      "[[   2  116]\n",
      " [   3 1129]]\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_clf = clf.predict(count_vect_test1)\n",
    "cm = confusion_matrix(y_test, y_pred_clf)\n",
    "    \n",
    "print('\\n********** [{}] **********\\n'.format(label))\n",
    "print('1. Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_clf)))\n",
    "print('2. The F-1 score of the model {}\\n'.format(f1_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('3. The recall score of the model {}\\n'.format(recall_score(y_test, y_pred_clf, average='weighted')))\n",
    "print('4. Classification Report:\\n{}\\n5. Confusion matrix:\\n{}\\n\\n\\n'.format(\n",
    "    classification_report(y_test, y_pred_clf), cm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
