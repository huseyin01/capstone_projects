{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "## Regular Expression\n",
    "import re\n",
    "\n",
    "## Arrays\n",
    "import numpy as np\n",
    "\n",
    "## DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "## Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from  sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import contractions\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    12080\n",
      "0     1192\n",
      "Name: rating_class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#reading the data\n",
    "df=pd.read_csv('data_capstone_2/nlp_reviews_cleaned.csv', delimiter=',')\n",
    "\n",
    "#creating the classes\n",
    "df['rating_class'] = df['rating'].apply(lambda x: 0 if x <= 2 else 1)\n",
    "\n",
    "#train data set reduced due to capacity of computing\n",
    "print(df.rating_class.value_counts())\n",
    "\n",
    "#splitting data set into train and test sets\n",
    "X = df['clean_text']\n",
    "y = df['rating_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_plot(y_test, y_pred, title, color):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    plt.clf()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=color)\n",
    "    classNames = ['Bad','Not bad']\n",
    "    plt.title(title, fontsize=20)\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "    tick_marks = np.arange(len(classNames))\n",
    "    plt.xticks(tick_marks, classNames, rotation=45, fontsize=15)\n",
    "    plt.yticks(tick_marks, classNames, fontsize=15)\n",
    "    s = [['TN','FP'], ['FN', 'TP']]\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            plt.text(j,i, str(s[i][j])+\" = \"+str(cm[i][j]), fontsize=15, \n",
    "                 fontweight='bold', horizontalalignment=\"center\")\n",
    "    return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CountVectorizer (Vectorizing the Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the word vector with CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(ngram_range=(1,1))\n",
    "count_vect_train = count_vect.fit_transform(X_train)\n",
    "count_vect_train = count_vect_train.toarray()\n",
    "count_vect_test = count_vect.transform(X_test)\n",
    "count_vect_test = count_vect_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary len : 24998\n",
      "Longest word   : combayerbdiseaseconcentrateouncedpbvzqfurefsrieutfqidsrkeywordsbayermitecontrolkeeps\n"
     ]
    }
   ],
   "source": [
    "# Getting the vocabulary length\n",
    "print('Vocabulary len :', len(count_vect.get_feature_names()))\n",
    "print('Longest word   :', max(count_vect.vocabulary_, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = count_vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Logistic Regression with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: logreg\n",
    "logreg_cv = LogisticRegression()\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "logreg_cv = GridSearchCV(logreg, log_params, cv=5)\n",
    "# Fit it to the traning set;\n",
    "logreg_cv.fit(count_vect_train, y_train)\n",
    "# Predict on the test set;\n",
    "y_pred_logreg_cv = logreg_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print(\"Tuned Logistic Regression Parameters: {}\\n\".format(logreg_cv.best_params_)) \n",
    "print(\"Best score is {}\\n\".format(logreg_cv.best_score_))\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_logreg_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_logreg_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_logreg_cv, \n",
    "                      title = 'Logistic Regression with CountVectorizing', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Linear SVM with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hyperparameter space\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "svm_params = {'C': Cs, 'gamma' : gammas}\n",
    "# Instantiate the classifier;\n",
    "svm=SVC(kernel='linear')\n",
    "# Instantiate the GridSearchCV object;\n",
    "svm_cv = GridSearchCV(svm, svm_params, cv=5)\n",
    "# Fit to the training set\n",
    "svm_cv.fit(count_vect_train, y_train)\n",
    "# Predict on the test set;\n",
    "y_pred_svm_cv = svm_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print(\"Linear SVM Best Parameters: {}\\n\".format(svm_cv.best_params_)) \n",
    "print(\"Best score is {}\\n\".format(svm_cv.best_score_))\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_svm_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_svm_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_svm_cv, title = 'Linear SVM with CountVectorizer', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Naive Bayes with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hyperparameter space;\n",
    "nb_params = {'alpha': [0.001, 0.01, 0.1, 1, 10, 100, 200]}\n",
    "# Instantiate the classifier;\n",
    "nb = MultinomialNB()\n",
    "# Instantiate the GridSearchCV object;\n",
    "nb_cv = GridSearchCV(nb, nb_params, cv=5)\n",
    "# Fit to the training set;\n",
    "nb_cv.fit(count_vect_train, y_train)\n",
    "# Predict on the test set;\n",
    "y_pred_nb_cv = nb_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print(\"Naive Bayes Best Parameter: {}\\n\".format(nb_cv.best_params_)) \n",
    "print(\"Best score is {}\\n\".format(nb_cv.best_score_))\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_nb_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_nb_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matriz with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_nb_cv, title = 'Naive Bayes with CountVectorizing', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Kernel SVM with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the hyperparameter space;\n",
    "Cs = [0.001, 0.01, 0.1, 1, 10]\n",
    "gammas = [0.001, 0.01, 0.1, 1]\n",
    "ksvm_params = {'C': Cs, 'gamma' : gammas}\n",
    "# Instantiate the classifier;\n",
    "ksvm=SVC(kernel='rbf')\n",
    "# Instantiate the GridSearchCV object;\n",
    "ksvm_cv = GridSearchCV(ksvm, ksvm_params, cv=5)\n",
    "# Fit to the training set\n",
    "ksvm_cv.fit(count_vect_train, y_train)\n",
    "# Predict the labels of the test set;\n",
    "y_pred_ksvm_cv = ksvm_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print(\"Kernel SVM Best Parameters: {}\\n\".format(ksvm_cv.best_params_)) \n",
    "print(\"Best score is {}\\n\".format(ksvm_cv.best_score_))\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_ksvm_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_ksvm_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Plotting the confusion matriz with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_ksvm_cv, title = 'Kernel SVM with CountVectorizing', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. KNeighbors with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the paramater spaces\n",
    "knn_params = {'n_neighbors': np.arange(1, 50)}\n",
    "# Instantiate the classifier: \n",
    "knn = KNeighborsClassifier()\n",
    "# Instantiate the GridSearchCV object;\n",
    "knn_cv = GridSearchCV(knn, knn_params, cv=5)\n",
    "# Fit it to the training set;\n",
    "knn_cv.fit(count_vect_train, y_train)\n",
    "# Predict on the test set;\n",
    "y_pred_knn_cv = knn_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print(\"KNN Best Parameters: {}\\n\".format(knn_cv.best_params_)) \n",
    "print(\"Best score is {}\\n\".format(knn_cv.best_score_))\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_knn_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_knn_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_knn_cv, title = 'KNN with CountVectorizer', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Random Forest with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimzation has not been done due to the limitations\n",
    "\n",
    "# Instantiate the classifier; \n",
    "rf_cv = RandomForestClassifier(n_estimators = 200, random_state=5)\n",
    "\n",
    "# Fit to the training set;\n",
    "rf_cv.fit(count_vect_train, y_train)\n",
    "\n",
    "# Predict on the test set;\n",
    "y_pred_rf_cv = rf_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_rf_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, y_pred_rf_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matriz with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_rf_cv, title = 'Random Forest with CountVectorizing', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7. Gradient Boosting with CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimzation has not been done due to the limitations\n",
    "\n",
    "# Instantiate the classifier; \n",
    "gb_cv = GradientBoostingClassifier()\n",
    "\n",
    "# Fit to the training set\n",
    "gb_cv.fit(count_vect_train, y_train)\n",
    "\n",
    "# Predict on the test set;\n",
    "y_pred_gb_cv = gb_cv.predict(count_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_gb_cv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (classification_report(y_test, y_pred_gb_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matriz with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_gb_cv, title = 'Gradient Boosting with CountVectorizing', color=plt.cm.cool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8. Comparision of CountVectorizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Comparision "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for converting the \"classification report\" results to a dataframe\n",
    "def pandas_classification_report(y_true, y_pred):\n",
    "    metrics_summary = precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred)\n",
    "\n",
    "    avg = list(precision_recall_fscore_support(\n",
    "            y_true=y_true, \n",
    "            y_pred=y_pred,\n",
    "            average='weighted'))\n",
    "\n",
    "    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n",
    "    class_report_df = pd.DataFrame(\n",
    "        list(metrics_summary),\n",
    "        index=metrics_sum_index)\n",
    "\n",
    "    support = class_report_df.loc['support']\n",
    "    total = support.sum() \n",
    "    avg[-1] = total\n",
    "\n",
    "    class_report_df['avg / total'] = avg\n",
    "\n",
    "    return class_report_df.T\n",
    "\n",
    "# Function for adding explanatory columns and organizing all dataframe\n",
    "def comparison_matrix(y_test, y_pred, label, vector):\n",
    "    df = pandas_classification_report(y_test, y_pred)\n",
    "    df = df[:2]\n",
    "    df['class']=['bad', 'not bad']\n",
    "    df['accuracy']= metrics.accuracy_score(y_test, y_pred)\n",
    "    df['model'] = label\n",
    "    df['vectorizer'] = vector\n",
    "    df = df[['vectorizer', 'model', 'accuracy', 'class', 'precision', 'recall', 'f1-score', 'support']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For loop for using \"comparison functions\" on \"CountVectorizing\" results\n",
    "\n",
    "frames_cv = [] # empty list for collecting dataframes\n",
    "y_preds_cv = [y_pred_logreg_cv, y_pred_svm_cv, y_pred_ksvm_cv, \n",
    "           y_pred_nb_cv, y_pred_knn_cv, y_pred_rf_cv, y_pred_gb_cv] #list for y_preds\n",
    "labels_cv = ['LogReg', 'SVM', 'Kernel SVM', 'Naive Bayes', 'KNN', 'RForest', 'GBoost'] # list for labels\n",
    "vector_cv = 'CountVect'\n",
    "for y_pred, label in zip(y_preds_cv, labels_cv):\n",
    "    df = comparison_matrix(y_test, y_pred, label, vector_cv)\n",
    "    frames_cv.append(df)\n",
    "\n",
    "# concatenating all dataframes\n",
    "df_cv = pd.concat(frames)\n",
    "\n",
    "df_cv2 = df_cv.set_index(['vectorizer', 'model', 'accuracy', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison Table - CountVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the comparision table\n",
    "print('\\nComparision Matrix of Modeling with CountVectorizing\\n\\n{}\\n'.format(df_cv2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(ngram_range=(1, 1))\n",
    "tfidf_vect_train = tfidf_vect.fit_transform(X_train)\n",
    "tfidf_vect_train = tfidf_vect_train.toarray()\n",
    "tfidf_vect_test = tfidf_vect.transform(X_test)\n",
    "tfidf_vect_test = tfidf_vect_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Logistic Regression with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression classifier: with already defined best parameters\n",
    "logreg_tv = LogisticRegression(C=0.001, penalty='l2')\n",
    "# Fit it to the data\n",
    "logreg_tv.fit(tfidf_vect_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred_logreg_tv = logreg_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_logreg_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_logreg_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_logreg_tv, \n",
    "                      title = 'Logistic Regression with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Linear SVM with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a SVC classifier: with already defined best parameters\n",
    "svm_tv=SVC(kernel='linear', C=0.001, gamma=0.001)\n",
    "# Fit to the training set\n",
    "svm_tv.fit(tfidf_vect_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred_svm_tv = svm_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_svm_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_svm_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_svm_tv, \n",
    "                      title = 'Linear SVM with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Naive Bayes with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a naive bayes classifier:\n",
    "nb_tv = MultinomialNB(alpha=100)\n",
    "# Fit to the training set\n",
    "nb_tv.fit(tfidf_vect_train, y_train)\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_nb_tv = nb_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_nb_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_nb_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_nb_tv, \n",
    "                      title = 'Naive Bayes with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Kernel SVM with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a naive bayes classifier:\n",
    "ksvm_tv = SVC(kernel='rbf', C=0.001, gamma=0.001)\n",
    "# Fit to the training set\n",
    "ksvm_tv.fit(tfidf_vect_train, y_train)\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_ksvm_tv = ksvm_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_ksvm_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_ksvm_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_ksvm_tv, \n",
    "                      title = 'Kernel SVM with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. KNN Classifier with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: \n",
    "knn_tv = KNeighborsClassifier(n_neighbors=2)\n",
    "# Fit it to the data\n",
    "knn_tv.fit(tfidf_vect_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred_knn_tv = knn_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_knn_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_knn_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_knn_tv, \n",
    "                      title = 'KNN with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Random Forest with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: \n",
    "rf_tv = RandomForestClassifier(n_estimators = 200, random_state=5)\n",
    "# Fit to the training set\n",
    "rf_tv.fit(tfidf_vect_train, y_train)\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_rf_tv = rf_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_rf_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_rf_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_rf_tv, \n",
    "                      title = 'KNN with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7. GradientBoosting with TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier; \n",
    "gb_tv = GradientBoostingClassifier()\n",
    "\n",
    "# Fit to the training set\n",
    "gb_tv.fit(tfidf_vect_train, y_train)\n",
    "\n",
    "# Predict on the test set;\n",
    "y_pred_gb_tv = gb_tv.predict(tfidf_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_gb_tv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_gb_tv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_gb_tv, \n",
    "                      title = 'KNN with TfidfVectorizing', color=plt.cm.Wistia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8. Comparision of TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop for using \"comparison functions\" on \"TfidfVectorizing\" results\n",
    "\n",
    "frames_tv = [] # empty list for collecting dataframes\n",
    "y_preds_tv = [y_pred_logreg_tv, y_pred_svm_tv, y_pred_ksvm_tv, \n",
    "           y_pred_nb_tv, y_pred_knn_tv, y_pred_rf_tv, y_pred_gb_tv] #list for y_preds\n",
    "labels_tv = ['LogReg', 'SVM', 'Kernel SVM', 'Naive Bayes', 'KNN', 'RForest', 'GBoost'] # list for labels\n",
    "vector_tv = 'TfidfVect'\n",
    "for y_pred, label in zip(y_preds_tv, labels_tv):\n",
    "    df = comparison_matrix(y_test, y_pred, label, vector_tv)\n",
    "    frames_tv.append(df)\n",
    "\n",
    "# concatenating all dataframes\n",
    "df_tv = pd.concat(frames_tv)\n",
    "\n",
    "df_tv2 = df_tv.set_index(['vectorizer', 'model', 'accuracy', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison table - TfidfVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the comparision matrix\n",
    "print('\\nComparision Matrix of Modeling with TfidfVectorizing\\n\\n{}\\n'.format(df_tv2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_vect = HashingVectorizer(n_features=2000, ngram_range=(1,1))\n",
    "hash_vect_train = hash_vect.fit_transform(X_train)\n",
    "hash_vect_train = hash_vect_train.toarray()\n",
    "hash_vect_test = hash_vect.transform(X_test)\n",
    "hash_vect_test = hash_vect_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Logistic Regression with HashingVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a logistic regression classifier: with already defined best parameters\n",
    "logreg_hv = LogisticRegression(C=0.001, penalty='l2')\n",
    "# Fit it to the data\n",
    "logreg_hv.fit(hash_vect_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred_logreg_hv = logreg_hv.predict(hash_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_logreg_hv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_logreg_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_logreg_hv, \n",
    "                      title = 'Logistic Regression with HashingVectorizing', color=plt.cm.spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Linear SVM with HashingVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a SVC classifier: with already defined best parameters\n",
    "svm_hv=SVC(kernel='linear', C=0.001, gamma=0.001)\n",
    "# Fit to the training set\n",
    "svm_hv.fit(hash_vect_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred_svm_hv = svm_hv.predict(hash_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_svm_hv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_svm_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_svm_hv, \n",
    "                      title = 'Linear SVM with HashingVectorizing', color=plt.cm.spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Kernel SVM with HashVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a naive bayes classifier:\n",
    "ksvm_hv = SVC(kernel='rbf', C=0.001, gamma=0.001)\n",
    "# Fit to the training set\n",
    "ksvm_hv.fit(hash_vect_train, y_train)\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_ksvm_hv = ksvm_hv.predict(hash_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_ksvm_hv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_ksvm_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_ksvm_hv, \n",
    "                      title = 'Kernel SVM with HashingVectorizing', color=plt.cm.spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. KNN Classifier with HashVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: \n",
    "knn_hv = KNeighborsClassifier(n_neighbors=2)\n",
    "# Fit it to the data\n",
    "knn_hv.fit(hash_vect_train, y_train)\n",
    "# Predict on the test data\n",
    "y_pred_knn_hv = knn_hv.predict(hash_vect_test)\n",
    "\n",
    "# Compute and print the scores\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_knn_hv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_knn_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_knn_hv, \n",
    "                      title = 'KNN with HashingVectorizing', color=plt.cm.spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Random Forest with HasVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier: \n",
    "rf_hv = RandomForestClassifier(n_estimators = 200, random_state=5)\n",
    "# Fit to the training set\n",
    "rf_hv.fit(hash_vect_train, y_train)\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred_rf_hv = rf_hv.predict(hash_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_rf_hv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_rf_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_rf_hv, \n",
    "                      title = 'Random Forest with HashingVectorizing', color=plt.cm.spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6. GradientBoosting with HashVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the classifier; \n",
    "gb_hv = GradientBoostingClassifier()\n",
    "\n",
    "# Fit to the training set\n",
    "gb_hv.fit(hash_vect_train, y_train)\n",
    "\n",
    "# Predict on the test set;\n",
    "y_pred_gb_hv = gb_hv.predict(hash_vect_test)\n",
    "\n",
    "# Compute and print the accuracy\n",
    "print('Accuarcy: {}\\n'.format(metrics.accuracy_score(y_test, y_pred_gb_hv)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute and print the classification report\n",
    "print (classification_report(y_test, y_pred_gb_hv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the confusion matrix with \"confusion_matrix_plot\" function\n",
    "confusion_matrix_plot(y_test, y_pred_gb_hv, \n",
    "                      title = 'GradientBoosting with HashingVectorizing', color=plt.cm.spring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7. Comparison of HashingVectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For loop for using \"comparison functions\" on \"HashingVectorizing\" results\n",
    "\n",
    "frames_hv = [] # empty list for collecting dataframes\n",
    "y_preds_hv = [y_pred_logreg_hv, y_pred_svm_hv, y_pred_ksvm_hv,\n",
    "           y_pred_knn_hv, y_pred_rf_hv, y_pred_gb_hv] #list for y_preds\n",
    "labels_hv = ['LogReg', 'SVM', 'Kernel SVM', 'KNN', 'RForest', 'GBoost'] # list for labels\n",
    "vector_hv = 'HashVect'\n",
    "for y_pred, label in zip(y_preds_hv, labels_hv):\n",
    "    df = comparison_matrix(y_test, y_pred, label, vector_hv)\n",
    "    frames_hv.append(df)\n",
    "\n",
    "# concatenating all dataframes\n",
    "df_hv = pd.concat(frames_hv)\n",
    "\n",
    "df_hv2 = df_hv.set_index(['vectorizer', 'model', 'accuracy', 'class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the comparision matrix\n",
    "print('\\nComparision Matrix of Modeling with HashingVectorizing\\n\\n{}\\n'.format(df_hv2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_all = frames_cv + frames_tv + frames_hv\n",
    "df_all = pd.concat(frames_all)\n",
    "df_all2 = df_all.set_index(['vectorizer', 'model', 'accuracy', 'class'])\n",
    "print('\\nComparision Table of All BOW Vectorizers\\n\\n{}\\n'.format(df_all2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
