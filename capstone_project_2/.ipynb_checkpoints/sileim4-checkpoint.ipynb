{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "## Regular Expression\n",
    "import re\n",
    "\n",
    "## Arrays\n",
    "import numpy as np\n",
    "\n",
    "## DataFrames\n",
    "import pandas as pd\n",
    "\n",
    "## Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "\n",
    "## Modeling\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "import contractions\n",
    "import spacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "## Warnings\n",
    "import warnings\n",
    "from scipy import stats\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('nlp_reviews_cleaned.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>customer</th>\n",
       "      <th>product</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>pos_feedback</th>\n",
       "      <th>neg_feedback</th>\n",
       "      <th>review_text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>tokens2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A1JZFGZEZVWQPY</td>\n",
       "      <td>B00002N674</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1308614400</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Great Hoses Good USA company that stands behin...</td>\n",
       "      <td>great hose good usa company stand behind produ...</td>\n",
       "      <td>['great', 'hose', 'good', 'usa', 'company', 's...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        customer     product  rating        time  pos_feedback  \\\n",
       "0           0  A1JZFGZEZVWQPY  B00002N674     4.0  1308614400             4   \n",
       "\n",
       "   neg_feedback                                        review_text  \\\n",
       "0             0  Great Hoses Good USA company that stands behin...   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0  great hose good usa company stand behind produ...   \n",
       "\n",
       "                                             tokens2  \n",
       "0  ['great', 'hose', 'good', 'usa', 'company', 's...  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Ratings')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAD8CAYAAABgmUMCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAFrBJREFUeJzt3X+w5XV93/HnS35oCkZALmSzP1gddmywo4g7SMYZx4guP0JcphGLbWVlcLaNJNGmkwj+URrUqXQ6aqkJKQ1rFqsiJbFsGRRX1HHaCciiCCLa3aCwy6/duLCY0Jig7/5xPlcOl/vjfOF+z7nLPh8zZ873+/5+vuf7vt+du6/7/XHOSVUhSdKoXjDpBiRJ+xeDQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqZODJ91AH44++uhavXr1pNuQpP3K7bff/tdVNbXQuOdlcKxevZpt27ZNug1J2q8kuW+UcZ6qkiR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpk96CI8krktwx9Hg8yfuSHJVka5Lt7fnINj5JLk+yI8mdSU4aeq0Nbfz2JBv66lmStLDegqOqvl9VJ1bVicBrgSeAzwMXATdX1Rrg5jYPcAawpj02AlcAJDkKuAR4HXAycMl02EiSxm9cp6pOBf6qqu4D1gObW30zcHabXg9cXQO3AEckWQacBmytqr1V9SiwFTh9TH1LkmYY1zvHzwU+26aPraqHAKrqoSTHtPpyYOfQOrtaba66JM1r2YpVPPzAzoUHPo/80vKVPLTr/l630XtwJDkUeCtw8UJDZ6nVPPWZ29nI4BQXq1at6tilpOejhx/YyXHvv2HSbYzVfZed1fs2xnGq6gzgm1X1SJt/pJ2Coj3vbvVdwMqh9VYAD85Tf5qqurKq1lbV2qmpBT+jS5L0LI0jON7BU6epALYA03dGbQCuH6qf1+6uOgXY105p3QSsS3Jkuyi+rtUkSRPQ66mqJP8IeAvwr4bKHwGuTXIBcD9wTqvfCJwJ7GBwB9b5AFW1N8kHgdvauEuram+ffUuS5tZrcFTVE8BLZ9R+xOAuq5ljC7hwjtfZBGzqo0dJUje+c1yS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmd9BocSY5Icl2S7yW5J8mvJjkqydYk29vzkW1sklyeZEeSO5OcNPQ6G9r47Uk29NmzJGl+fR9x/Gfgi1X1j4FXA/cAFwE3V9Ua4OY2D3AGsKY9NgJXACQ5CrgEeB1wMnDJdNhIksavt+BI8ovAG4CrAKrq76vqMWA9sLkN2wyc3abXA1fXwC3AEUmWAacBW6tqb1U9CmwFTu+rb0nS/Po84ng5sAf4ZJJvJfnTJIcBx1bVQwDt+Zg2fjmwc2j9Xa02V/1pkmxMsi3Jtj179iz+TyNJAvoNjoOBk4Arquo1wN/y1Gmp2WSWWs1Tf3qh6sqqWltVa6empp5Nv5KkEfQZHLuAXVV1a5u/jkGQPNJOQdGedw+NXzm0/grgwXnqkqQJ6C04quphYGeSV7TSqcB3gS3A9J1RG4Dr2/QW4Lx2d9UpwL52KusmYF2SI9tF8XWtJkmagIN7fv3fAT6d5FDgXuB8BmF1bZILgPuBc9rYG4EzgR3AE20sVbU3yQeB29q4S6tqb899S5Lm0GtwVNUdwNpZFp06y9gCLpzjdTYBmxa3O0nSs+E7xyVJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktSJwSFJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpk16DI8kPk9yV5I4k21rtqCRbk2xvz0e2epJcnmRHkjuTnDT0Ohva+O1JNvTZsyRpfuM44vi1qjqxqta2+YuAm6tqDXBzmwc4A1jTHhuBK2AQNMAlwOuAk4FLpsNGkjR+kzhVtR7Y3KY3A2cP1a+ugVuAI5IsA04DtlbV3qp6FNgKnD7upiVJA30HRwFfSnJ7ko2tdmxVPQTQno9p9eXAzqF1d7XaXHVJ0gQc3PPrv76qHkxyDLA1yffmGZtZajVP/ekrD4JpI8CqVaueTa+SpBH0esRRVQ+2593A5xlco3iknYKiPe9uw3cBK4dWXwE8OE995raurKq1VbV2ampqsX8USVLTW3AkOSzJi6engXXAd4AtwPSdURuA69v0FuC8dnfVKcC+dirrJmBdkiPbRfF1rSZJmoA+T1UdC3w+yfR2PlNVX0xyG3BtkguA+4Fz2vgbgTOBHcATwPkAVbU3yQeB29q4S6tqb499S5Lm0VtwVNW9wKtnqf8IOHWWegEXzvFam4BNi92jJKk73zkuSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUSefgaF/h+qo+mpEkLX0jBUeSryX5xSRHAd8GPpnko/22JklaikY94nhJVT0O/FPgk1X1WuDN/bUlSVqqRg2Og5MsA94O3NBjP5KkJW7U4LgUuAnYUVW3JXk5sH2UFZMclORbSW5o8y9LcmuS7Uk+l+TQVn9hm9/Rlq8eeo2LW/37SU7r8gNKkhbXSMFRVf+jql5VVe9p8/dW1W+OuI33AvcMzV8GfKyq1gCPAhe0+gXAo1V1PPCxNo4kJwDnAq8ETgf+OMlBI25bkrTIDh5lUJLLZynvA7ZV1fXzrLcC+HXgw8DvJQnwJuCftyGbgX8PXAGsb9MA1wGfaOPXA9dU1U+AHyTZAZwM/OUovUuSFteop6peBJzI4PTUduBVwFHABUk+Ps96Hwf+APhZm38p8FhVPdnmdwHL2/RyYCdAW76vjf95fZZ1JEljNtIRB3A88Kbp//CTXAF8CXgLcNdsKyQ5C9hdVbcneeN0eZahtcCy+dYZ3t5GYCPAqlWr5vxBJEnPzahHHMuBw4bmDwN+uap+CvxkjnVeD7w1yQ+Baxicovo4cESS6cBaATzYpncBKwHa8pcAe4frs6zzc1V1ZVWtraq1U1NTI/5YkqSuRg2O/wjckeSTSf4M+Bbwn5IcBnx5thWq6uKqWlFVqxlc3P5KVf0L4KvA29qwDcD0NZItbZ62/CtVVa1+brvr6mXAGuAbHX5GSdIiGulUVVVdleRGBhelA3ygqqb/6v/9jtt8P3BNkg8xCKCrWv0q4FPt4vdeBmFDVd2d5Frgu8CTwIXtSEeSNAGjXuOAwdHJnrbO8UmOr6qvj7JiVX0N+FqbvpdBAM0c83fAOXOs/2EGd2ZJkiZs1NtxLwP+GXA3T90hVcBIwSFJev4Y9YjjbOAV7b0UkqQD2KgXx+8FDumzEUnS/mHUI44nGNxVdTNDt99W1e/20pUkackaNTi2tIck6QA36u24m/tuRJK0f5g3OJJcW1VvT3IXs3zMR1X5FbKSdIBZ6Ijjve35rL4bkSTtH+a9q6qqHmqT76mq+4YfwHv6b0+StNSMejvuW2apnbGYjUiS9g8LXeP4LQZHFi9PcufQohcD/6fPxiRJS9NC1zg+A3wB+A/ARUP1H1fV3t66kiQtWfMGR1XtY/BNfO8ASHIMg28DPDzJ4VV1f/8tSpKWklE/5PA3gI8CvwzsBo4D7gFe2V9rkhbTshWrePiBnQsPlBYw6jvHPwScAny5ql6T5NdoRyGS9g8PP7CT495/w6TbGKv7LvOdBH0Y9a6qf6iqHwEvSPKCqvoqcGKPfUmSlqhRjzgeS3I4g+/f+HSS3Qy+jU+SdIAZ9YhjPYNPyP03wBeBvwJ+o6+mJElL16gfcvi3bfJnwOYkBzH4TvBP99WYJGlpmveII8kvJrk4ySeSrMvAbzP4Yqe3j6dFSdJSstARx6eAR4G/BN4N/D5wKLC+qu7ouTdJ0hK00DWOl1fVu6rqvzK4/XYtcNYooZHkRUm+keTbSe5O8oet/rIktybZnuRzSQ5t9Re2+R1t+eqh17q41b+f5LRn+8NKkp67hYLjH6YnquqnwA+q6scjvvZPgDdV1asZ3Lp7epJTgMuAj1XVGgZHMxe08RcAj1bV8cDH2jiSnMDgesorgdOBP27XWCRJE7BQcLw6yePt8WPgVdPTSR6fb8Ua+Js2e0h7FPAm4LpW3wyc3abXt3na8lOTpNWvqaqfVNUPgB3AyR1+RknSIlros6qe01/27cjgduB44I8Y3Mb7WFVNvwdkF7C8TS8HdrbtPplkH/DSVr9l6GWH15Ekjdmo7+N4Vqrqp1V1IrCCwVHCr8w2rD1njmVz1Z8mycYk25Js27Nnz7NtWZK0gF6DY1pVPQZ8jcHnXR2RZPpIZwXwYJveBawEaMtfAuwdrs+yzvA2rqyqtVW1dmpqqo8fQ5JEj8GRZCrJEW36F4A3M/hE3a8Cb2vDNgDXt+ktbZ62/CtVVa1+brvr6mXAGuAbffUtSZrfqJ9V9Wws46l3mb8AuLaqbkjyXeCaJB8CvgVc1cZfBXwqyQ4GRxrnAlTV3UmuBb7L4POxLmx3eEmSJqC34KiqO4HXzFK/l1nuiqqqvwPOmeO1Pgx8eLF7lCR1N5ZrHJKk5w+DQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkddJbcCRZmeSrSe5JcneS97b6UUm2Jtneno9s9SS5PMmOJHcmOWnotTa08duTbOirZ0nSwvo84ngS+LdV9SvAKcCFSU4ALgJurqo1wM1tHuAMYE17bASugEHQAJcArwNOBi6ZDhtJ0vj1FhxV9VBVfbNN/xi4B1gOrAc2t2GbgbPb9Hrg6hq4BTgiyTLgNGBrVe2tqkeBrcDpffUtSZrfWK5xJFkNvAa4FTi2qh6CQbgAx7Rhy4GdQ6vtarW56pKkCeg9OJIcDvw58L6qeny+obPUap76zO1sTLItybY9e/Y8u2YlSQvqNTiSHMIgND5dVX/Ryo+0U1C0592tvgtYObT6CuDBeepPU1VXVtXaqlo7NTW1uD+IJOnn+ryrKsBVwD1V9dGhRVuA6TujNgDXD9XPa3dXnQLsa6eybgLWJTmyXRRf12qSpAk4uMfXfj3wTuCuJHe02geAjwDXJrkAuB84py27ETgT2AE8AZwPUFV7k3wQuK2Nu7Sq9vbYtyRpHr0FR1X9b2a/PgFw6izjC7hwjtfaBGxavO4kSc+W7xyXJHVicEiSOjE4JEmdGBySpE4MDklSJ33ejistWctWrOLhB3YuPFDSMxgcOiA9/MBOjnv/DZNuY6zuu+ysSbeg5wlPVUmSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1InBIUnqxOCQJHVicEiSOjE4JEmdGBySpE4MDklSJwaHJKkTg0OS1ElvwZFkU5LdSb4zVDsqydYk29vzka2eJJcn2ZHkziQnDa2zoY3fnmRDX/1KkkbT5xHHnwGnz6hdBNxcVWuAm9s8wBnAmvbYCFwBg6ABLgFeB5wMXDIdNpKkyegtOKrq68DeGeX1wOY2vRk4e6h+dQ3cAhyRZBlwGrC1qvZW1aPAVp4ZRpKkMRr3NY5jq+ohgPZ8TKsvB4a/x3NXq81Vf4YkG5NsS7Jtz549i964JGlgqVwczyy1mqf+zGLVlVW1tqrWTk1NLWpzkqSnjDs4HmmnoGjPu1t9F7ByaNwK4MF56pKkCRl3cGwBpu+M2gBcP1Q/r91ddQqwr53KuglYl+TIdlF8XatJkibk4L5eOMlngTcCRyfZxeDuqI8A1ya5ALgfOKcNvxE4E9gBPAGcD1BVe5N8ELitjbu0qmZecJckjVFvwVFV75hj0amzjC3gwjleZxOwaRFbkyQ9B0vl4rgkaT9hcEiSOjE4JEmdGBySpE56uziu/ceyFat4+IGdCw+UJAwOAQ8/sJPj3n/DpNsYq/suO2vSLUj7LU9VSZI6MTgkSZ0YHJKkTrzGMQsvFkvS3AyOWRxoF4u9UCypC09VSZI6MTgkSZ0YHJKkTgwOSVInBockqRODQ5LUicEhSerE4JAkdWJwSJI62W+CI8npSb6fZEeSiybdjyQdqPaL4EhyEPBHwBnACcA7kpww2a4k6cC0XwQHcDKwo6ruraq/B64B1k+4J0k6IO0vwbEcGP642l2tJkkas1TVpHtYUJJzgNOq6t1t/p3AyVX1O0NjNgIb2+wrgO8/h00eDfz1c1i/L/bVjX11Y1/dPB/7Oq6qphYatL98rPouYOXQ/ArgweEBVXUlcOVibCzJtqpauxivtZjsqxv76sa+ujmQ+9pfTlXdBqxJ8rIkhwLnAlsm3JMkHZD2iyOOqnoyyW8DNwEHAZuq6u4JtyVJB6T9IjgAqupG4MYxbW5RTnn1wL66sa9u7KubA7av/eLiuCRp6dhfrnFIkpaIAzY4kmxKsjvJd+ZYniSXt484uTPJSUukrzcm2Zfkjvb4d2PoaWWSrya5J8ndSd47y5ix768R+xr7/mrbfVGSbyT5duvtD2cZ88Ikn2v77NYkq5dIX+9Ksmdon727777adg9K8q0kN8yybOz7asS+JrKv2rZ/mOSutt1tsyzv73eyqg7IB/AG4CTgO3MsPxP4AhDgFODWJdLXG4EbxryvlgEntekXA/8XOGHS+2vEvsa+v9p2Axzepg8BbgVOmTHmPcCftOlzgc8tkb7eBXxiAvvs94DPzPbvNYl9NWJfE9lXbds/BI6eZ3lvv5MH7BFHVX0d2DvPkPXA1TVwC3BEkmVLoK+xq6qHquqbbfrHwD088537Y99fI/Y1EW0//E2bPaQ9Zl5QXA9sbtPXAacmyRLoa+ySrAB+HfjTOYaMfV+N2NdS1tvv5AEbHCNYyh9z8qvtVMMXkrxynBtupwhew+Av1WET3V/z9AUT2l/tFMcdwG5ga1XNuc+q6klgH/DSJdAXwG+20xvXJVk5y/LF9nHgD4CfzbF8IvtqhL5g/PtqWgFfSnJ7Bp+cMVNvv5MGx9xm+2tm4n+ZAd9k8LEArwb+C/A/x7XhJIcDfw68r6oen7l4llXGsr8W6Gti+6uqflpVJzL4pIOTk/yTGUMmss9G6Ot/Aaur6lXAl3nqL/1eJDkL2F1Vt883bJZar/tqxL7Guq9meH1VncTgU8MvTPKGGct722cGx9wW/JiTSaiqx6dPNdTgvS2HJDm67+0mOYTBf86frqq/mGXIRPbXQn1Nan/N6OEx4GvA6TMW/XyfJTkYeAljPE05V19V9aOq+kmb/W/Aa3tu5fXAW5P8kMEnX78pyX+fMWYS+2rBviawr4a3/WB73g18nsGniA/r7XfS4JjbFuC8dmfCKcC+qnpo0k0l+aXpc7tJTmbwb/ijnrcZ4Crgnqr66BzDxr6/RulrEvurbWsqyRFt+heANwPfmzFsC7ChTb8N+Eq1q5qT7GvGefC3Mrh21JuquriqVlTVagYXvr9SVf9yxrCx76tR+hr3vhra7mFJXjw9DawDZt6J2dvv5H7zzvHFluSzDO64OTrJLuASBhcKqao/YfAu9TOBHcATwPlLpK+3Ab+V5Eng/wHn9v0LxOAvr3cCd7Vz4wAfAFYN9TWJ/TVKX5PYXzC442tzBl9C9gLg2qq6IcmlwLaq2sIg9D6VZAeDv57PXSJ9/W6StwJPtr7eNYa+nmEJ7KtR+prUvjoW+Hz7m+hg4DNV9cUk/xr6/530neOSpE48VSVJ6sTgkCR1YnBIkjoxOCRJnRgckqRODA5JUicGhySpE4NDktTJ/wfSMHC77eUFDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(df.rating, edgecolor='k', bins=5)\n",
    "plt.ylabel('Ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rating_class'] = df['rating'].apply(lambda x: 0 if x <= 3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10421\n",
       "0     2851\n",
       "Name: rating_class, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rating_class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df['clean_text']\n",
    "target = df['rating_class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, target, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(ngram_range=(1,1), min_df=0, max_df=1)\n",
    "count_vect_train = count_vect.fit_transform(X_train)\n",
    "count_vect_train = count_vect_train.toarray()\n",
    "count_vect_test = count_vect.transform(X_test)\n",
    "count_vect_test = count_vect_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ggggggggreat aqm impressed cost quality product also impressed fast shipment amazon received day ha not kinked great hose one left yard season even ran across driveway lasted good year abuse would recommend anyone thanks\n",
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[5])\n",
    "print(count_vect_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary len : 13318\n",
      "Longest word   : combayerbdiseaseconcentrateouncedpbvzqfurefsrieutfqidsrkeywordsbayermitecontrolkeeps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Vocabulary len :', len(count_vect.get_feature_names()))\n",
    "print('Longest word   :', max(count_vect.vocabulary_, key=len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = RegexpTokenizer(r'\\w+')\n",
    "#tokenizer.tokenize('Eighty-seven miles to go, yet.  Onward!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aarp</th>\n",
       "      <th>abated</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abc</th>\n",
       "      <th>abeginning</th>\n",
       "      <th>abf</th>\n",
       "      <th>abhor</th>\n",
       "      <th>ably</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>abnormally</th>\n",
       "      <th>...</th>\n",
       "      <th>zipperlock</th>\n",
       "      <th>zoey</th>\n",
       "      <th>zoisa</th>\n",
       "      <th>zoned</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zoomed</th>\n",
       "      <th>zoysia</th>\n",
       "      <th>zrfor</th>\n",
       "      <th>zthe</th>\n",
       "      <th>zzzzt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 13318 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aarp  abated  abbreviated  abc  abeginning  abf  abhor  ably  abnormal  \\\n",
       "0     0       0            0    0           0    0      0     0         0   \n",
       "1     0       0            0    0           0    0      0     0         0   \n",
       "2     0       0            0    0           0    0      0     0         0   \n",
       "3     0       0            0    0           0    0      0     0         0   \n",
       "4     0       0            0    0           0    0      0     0         0   \n",
       "\n",
       "   abnormally  ...    zipperlock  zoey  zoisa  zoned  zoo  zoomed  zoysia  \\\n",
       "0           0  ...             0     0      0      0    0       0       0   \n",
       "1           0  ...             0     0      0      0    0       0       0   \n",
       "2           0  ...             0     0      0      0    0       0       0   \n",
       "3           0  ...             0     0      0      0    0       0       0   \n",
       "4           0  ...             0     0      0      0    0       0       0   \n",
       "\n",
       "   zrfor  zthe  zzzzt  \n",
       "0      0     0      0  \n",
       "1      0     0      0  \n",
       "2      0     0      0  \n",
       "3      0     0      0  \n",
       "4      0     0      0  \n",
       "\n",
       "[5 rows x 13318 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "#vocab = count_vect.get_feature_names()\n",
    "pd.DataFrame(count_vect_train, columns=vocab).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.79 (+/- 0.00) [Logistic Regression]\n",
      "Accuracy: 0.79 (+/- 0.00) [Random Forest]\n",
      "Accuracy: 0.21 (+/- 0.00) [Naive Bayes]\n",
      "Accuracy: 0.79 (+/- 0.00) [Ensemble]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.classifier import EnsembleVoteClassifier\n",
    "import numpy as np\n",
    "\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf = EnsembleVoteClassifier(clfs=[clf1, clf2, clf3], weights=[1,1,1])\n",
    "\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']\n",
    "for clf, label in zip([clf1, clf2, clf3, eclf], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, count_vect_train, y_train, \n",
    "                                              cv=5, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" \n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12 µs, sys: 5 µs, total: 17 µs\n",
      "Wall time: 922 µs\n",
      "5-fold cross validation:\n",
      "\n",
      "Accuracy: 0.79 (+/- 0.00) [KNN]\n",
      "Accuracy: 0.79 (+/- 0.00) [SVM]\n",
      "Accuracy: 0.79 (+/- 0.00) [Kernel SVM]\n",
      "Accuracy: 0.79 (+/- 0.00) [Decision Tree]\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf4 = KNeighborsClassifier()\n",
    "clf5 = SVC(kernel = 'linear')\n",
    "clf6 = SVC(kernel = 'rbf')\n",
    "clf7 = DecisionTreeClassifier(criterion = 'entropy', random_state = 1)\n",
    "\n",
    "print('5-fold cross validation:\\n')\n",
    "\n",
    "labels = ['KNN', 'SVM', 'Kernel SVM', 'Decision Tree']\n",
    "\n",
    "for clf, label in zip([clf4, clf5, clf6, clf7], labels):\n",
    "\n",
    "    scores = model_selection.cross_val_score(clf, count_vect_train, y_train, \n",
    "                                              cv=5, \n",
    "                                              scoring='accuracy')\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\"\n",
    "          % (scores.mean(), scores.std(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Required argument 'object' (pos 1) not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-c26b682634a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Logistic Regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Random Forest'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Naive Bayes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ensemble'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m for clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n",
      "\u001b[0;31mTypeError\u001b[0m: Required argument 'object' (pos 1) not found"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import matplotlib.gridspec as gridspec\n",
    "import itertools\n",
    "\n",
    "gs = gridspec.GridSpec(2, 2)\n",
    "y=np.array(y_train)\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "y= np.array()\n",
    "labels = ['Logistic Regression', 'Random Forest', 'Naive Bayes', 'Ensemble']\n",
    "for clf, lab, grd in zip([clf1, clf2, clf3, eclf],\n",
    "                         labels,\n",
    "                         itertools.product([0, 1], repeat=2)):\n",
    "\n",
    "    clf.fit(count_vect_train, y)\n",
    "    ax = plt.subplot(gs[grd[0], grd[1]])\n",
    "    fig = plot_decision_regions(X=count_vect_train, y=y, clf=clf)\n",
    "    plt.title(lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7531645569620253\n"
     ]
    }
   ],
   "source": [
    "logreg_CV = LogisticRegression(multi_class='multinomial', solver='newton-cg',class_weight='balanced',\n",
    "                              C=1.0,n_jobs=-1, random_state=5)\n",
    "logreg_CV.fit(count_vect_train, y_train)\n",
    "y_pred_lr_CV = logreg_CV.predict(count_vect_test)\n",
    "print('Accuracy :', metrics.accuracy_score(y_test, y_pred_lr_CV))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_english_removal(text):\n",
    "    words = set(nltk.corpus.words.words())\n",
    "    text = \" \".join(w for w in nltk.wordpunct_tokenize(text) \\\n",
    "         if w.lower() in words or not w.isalpha())    \n",
    "    return text\n",
    "\n",
    "df['clean_text2']=df[\"clean_text\"].apply(non_english_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "text2 = df['clean_text2']\n",
    "target2 = df['rating_class']\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(text2, target2, test_size=0.25, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect2 = CountVectorizer(ngram_range=(1,1), min_df=0, max_df=1)\n",
    "count_vect_train2 = count_vect2.fit_transform(X_train2)\n",
    "count_vect_train2 = count_vect_train2.toarray()\n",
    "count_vect_test2 = count_vect2.transform(X_test2)\n",
    "count_vect_test2 = count_vect_test2.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "logreg_CV = LogisticRegression(multi_class='multinomial', solver='newton-cg',class_weight='balanced',\n",
    "                              C=1.0,n_jobs=-1, random_state=5)\n",
    "logreg_CV.fit(count_vect_train2, y_train2)\n",
    "y_pred_lr_CV2 = logreg_CV.predict(count_vect_test2)\n",
    "print('Accuracy :', metrics.accuracy_score(y_test2, y_pred_lr_CV2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using naive bayes\n",
    "\n",
    "# import and instantiate a Multinomial Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 360 ms, sys: 377 ms, total: 737 ms\n",
      "Wall time: 931 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(count_vect_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_nb2 = nb.predict(count_vect_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.781796262808921"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test2, y_pred_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = pd.Series(' '.join(df['clean_text2']).split()).value_counts()[-3690:]\n",
    "freq = list(freq.index)\n",
    "df['clean_text2'] = df['clean_text2'].apply(lambda x: \" \".join(x for x in x.split() if x not in freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.03 s, sys: 1.17 s, total: 2.2 s\n",
      "Wall time: 3.48 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3rd NB\n",
    "\n",
    "# train the model using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "%time nb.fit(count_vect_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make class predictions for X_test_dtm\n",
    "y_pred_nb2 = nb.predict(count_vect_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7784810126582279"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "metrics.accuracy_score(y_test2, y_pred_nb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq2 = pd.Series(' '.join(df['clean_text2']).split()).value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not       29075\n",
       "wa        11225\n",
       "one       10041\n",
       "use        8447\n",
       "would      7696\n",
       "work       7483\n",
       "like       7284\n",
       "get        6999\n",
       "feeder     6891\n",
       "trap       6768\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
